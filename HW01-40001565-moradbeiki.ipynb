{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a1d738",
   "metadata": {},
   "source": [
    "# سوال اول "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcaf474",
   "metadata": {},
   "source": [
    "اولین مرحله اضافه کردن کتابخانه هاست در این قسمت فقط از کتابخانه نامپای استفاده شده است "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c19766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461bd84",
   "metadata": {},
   "source": [
    "در اولین مرحله باید محیط بازی خود را بسازیم "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499afece",
   "metadata": {},
   "source": [
    "برای ساخت محیط بازی خود ابتدا نیاز داریم حرکت را برای عامل تعریف کنیم "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814591a",
   "metadata": {},
   "source": [
    "از ان جا که هر خانه که عامل در ان قرار دارد مربعی است و در صورت سوال گفته شده 4 حرکت در هر خانه میتواند انجام دهد بنابراین داریم:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9713e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#بالا\n",
    "up=0\n",
    "#پایین\n",
    "down=1\n",
    "#چپ\n",
    "left=2\n",
    "#راست\n",
    "right=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cda8e1",
   "metadata": {},
   "source": [
    "در این قسمت دو متغیر را تعریف میکنیم تا در ادامه کد ها راحت باشیم متغیر اول تعداد خانه هایی که عامل میتواند در محیط باشد است و متغیر دوم تعداد حرکت هایی که عامل میتواند در محیط به طور کلی داشته باشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2e9808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noS=64 #زمین بازی 8*8 است یعنی به تعداد 64 حالت دارد\n",
    "noA=4 #تعداد اعمال عامل در محیط که شامل حرکت به بالا، پایین، چپ و راست است"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2db9a",
   "metadata": {},
   "source": [
    "حال باید حالت ها را مشخص کنیم از انجا که گفتیم ما 64 خانه داریم پس یک متغیر تعریف میکنیم که ارایه ای است شامل 64 خانه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec037a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S=range(noS) #ارایه ای شامل 64 حالت که عامل میتواند در محیط باشد"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998a995",
   "metadata": {},
   "source": [
    "از ان جا که در صورت سوال گفته شده ما پاداش همه حرکت ها را صفر در نظر میگیریم و خانه اخر که هدف ماست را فقط 100 در نظر میگیریم بنابراین پاداش برابر 0  تعیین میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c94a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward =0 # پاداش هر عمل عامل در محیط غیر حالت هدف 0 در نظر گرفته شده است "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e606d89",
   "metadata": {},
   "source": [
    "حال باید خانه شروع حرکت عامل و خانه هدف عامل را در این زمین 8 در 8 مشخص کنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16e2a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_state = lambda s: s==24 or s==noS-1 #تعریف خانه شروع و پایان برای عامل "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643135a",
   "metadata": {},
   "source": [
    "در این قسمت همانطور که در صورت سوال هم مطرح شده در محیط بعضی خانه ها دیوار است و باید ان ها را مشخص کنیم تا عامل در ان جا قرار نگیرد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e945391",
   "metadata": {},
   "outputs": [],
   "source": [
    "wall=[12,26,34,42,46,54,62] #دیوارهایی که در محیط بازی وجود دارد و عامل در این حالات نمیتواند وارد شود"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01c4ed",
   "metadata": {},
   "source": [
    "در این قسمت میخواهیم برای عامل محیط را بسازیم و به هر کدام احتمال حرکت عامل را در محیط بدهیم برای این کار باید خانه های اطراف محیط 8 در8 را تعریف کنیم به طوریکه عامل بیشتر از 8 در 8 نتواند جلو برود و در همان محدوده حرکت کند از طرفی هم باید عمل هایی را برای عامل تعریف کنیم که عامل در دیوار ها نتواند وارد شود و بعد حرکت به سمت دیوار در همان ناحیه بماند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94079587",
   "metadata": {},
   "source": [
    "یک دیکشنری تعریف میکنیم و برای هر عمل خانه هایی که میتواند برود را مشخص میکنیم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ab517",
   "metadata": {},
   "source": [
    "به این صورت که به ازای هر عمل و هر حالت که عامل در ان است 3 مورد را در خروجی نمایش میدهیم اولین حالت بعدی که عامل در ان قرار میگیرد برای مثال اگر عامل در خانه 0 باشد با حرکت به بالا عامب به خانه 8 میرود"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d49f050",
   "metadata": {},
   "source": [
    "دومین مورد احتمال اینکه این حرکت را انجام دهد را تعیین میکنیم و سومین هم پاداشی که از این عمل به دست می اورد را در خروجی نمایش میدهیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c9f36340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ساخت محیط\n",
    "P=dict()\n",
    "for s in S: # برای کلیه حالات \n",
    "    P[s]=dict()\n",
    "    # اگر عامل در خانه هدف قرار گیرد به ازای هر عمل حالت بعدی را همان خانه و احتمال رسیدن\n",
    "    #را 0.25 و پاداش عامل در همان حالت را 100 در نظر بگیرد\n",
    "    if (terminal_state(s)):  \n",
    "        P[s][up]=(s,0.25,100) \n",
    "        P[s][down]=(s,0.25,100)\n",
    "        P[s][right]=(s,0.25,100)\n",
    "        P[s][left]=(s,0.25,100)\n",
    "    else:# یعنی عامل به هدف نرسیده \n",
    "        \n",
    "    #اگر عامل در 8 خانه انتها به هدف است یعنی در ضلع بالای مربع و عمل بالا رفتن میخواهد انجام دهد\n",
    "    # حالت بعدی را همان حالت در نظر بگیرد و از مربع 8 در 8 بیرون نرود\n",
    "        next_s= s if(64-s<=8) else s+8  \n",
    "        \n",
    "        #اگر عامل با عمل بالا رفتن به یکی از حالت های دیوار برخورد میکند در همان خانه باقی بماند\n",
    "        if next_s in wall:\n",
    "            P[s][up]=(s,0.25,0)\n",
    "            \n",
    "        #در غیر این صورت 8 خانه به خانه ای که در ان قرار دارد اضافه شود\n",
    "        else:\n",
    "            P[s][up]=(next_s,0.25,reward)\n",
    "        \n",
    "    #اگر عامل در 8 خانه ابتدایی است یعنی در ضلع پایین مربع و عمل پایین رفتن میخواهد انجام دهد\n",
    "    # حالت بعدی را همان حالت در نظر بگیرد و از مربع 8 در 8 بیرون نرود\n",
    "        next_s= s if(s<8) else s-8\n",
    "        \n",
    "        #اگر عامل با عمل پایین رفتن به یکی از حالت های دیوار برخورد میکند در همان خانه باقی بماند\n",
    "        if next_s in wall:\n",
    "            P[s][down]=(s,0.25,0)\n",
    "            \n",
    "        #در غیر این صورت 8 خانه از خانه ای که در ان قرار دارد کم شود    \n",
    "        else:\n",
    "            P[s][down]=(next_s,0.25,reward)\n",
    "            \n",
    "    #اگر عامل در خانه های سمت چپی است یعنی در ضلع سمت چپی مربع و عمل چپ رفتن میخواهد انجام دهد\n",
    "    # حالت بعدی را همان حالت در نظر بگیرد و از مربع 8 در 8 بیرون نرود    \n",
    "        next_s= s if((s+1)%8==0) else s+1\n",
    "        \n",
    "        #اگر عامل با عمل چپ رفتن به یکی از حالت های دیوار برخورد میکند در همان خانه باقی بماند\n",
    "        if next_s in wall:\n",
    "            P[s][left]=(s,0.25,0)\n",
    "            \n",
    "        #در غیر این صورت 1 خانه از خانه ای که در ان قرار دارد کم شود\n",
    "        else:\n",
    "            P[s][left]=(next_s,0.25,reward)\n",
    "        \n",
    "    #اگر عامل در خانه های سمت راستی است یعنی در ضلع سمت راست مربع و عمل راست رفتن میخواهد انجام دهد\n",
    "    # حالت بعدی را همان حالت در نظر بگیرد و از مربع 8 در 8 بیرون نرود\n",
    "        next_s= s if(s%8==0) else s-1\n",
    "        \n",
    "        #اگر عامل با عمل راست رفتن به یکی از حالت های دیوار برخورد میکند در همان خانه باقی بماند\n",
    "        if next_s in wall:\n",
    "            P[s][right]=(s,0.25,0)\n",
    "            \n",
    "        #در غیر این صورت 1 خانه به خانه ای که در ان قرار دارد اضافه شود\n",
    "        else:\n",
    "            P[s][right]=(next_s,0.25,reward)\n",
    "            \n",
    "        #در خانه هایی که دیوار در ان قرار دارد صفر در نظر بگیر\n",
    "for s in S:\n",
    "    if s in wall:\n",
    "        P[s][left]=(s,0,0)\n",
    "        P[s][right]=(s,0,0)\n",
    "        P[s][down]=(s,0,0)\n",
    "        P[s][up]=(s,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1217079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: (8, 0.25, 0), 1: (0, 0.25, 0), 2: (1, 0.25, 0), 3: (0, 0.25, 0)},\n",
       " 1: {0: (9, 0.25, 0), 1: (1, 0.25, 0), 2: (2, 0.25, 0), 3: (0, 0.25, 0)},\n",
       " 2: {0: (10, 0.25, 0), 1: (2, 0.25, 0), 2: (3, 0.25, 0), 3: (1, 0.25, 0)},\n",
       " 3: {0: (11, 0.25, 0), 1: (3, 0.25, 0), 2: (4, 0.25, 0), 3: (2, 0.25, 0)},\n",
       " 4: {0: (4, 0.25, 0), 1: (4, 0.25, 0), 2: (5, 0.25, 0), 3: (3, 0.25, 0)},\n",
       " 5: {0: (13, 0.25, 0), 1: (5, 0.25, 0), 2: (6, 0.25, 0), 3: (4, 0.25, 0)},\n",
       " 6: {0: (14, 0.25, 0), 1: (6, 0.25, 0), 2: (7, 0.25, 0), 3: (5, 0.25, 0)},\n",
       " 7: {0: (15, 0.25, 0), 1: (7, 0.25, 0), 2: (7, 0.25, 0), 3: (6, 0.25, 0)},\n",
       " 8: {0: (16, 0.25, 0), 1: (0, 0.25, 0), 2: (9, 0.25, 0), 3: (8, 0.25, 0)},\n",
       " 9: {0: (17, 0.25, 0), 1: (1, 0.25, 0), 2: (10, 0.25, 0), 3: (8, 0.25, 0)},\n",
       " 10: {0: (18, 0.25, 0), 1: (2, 0.25, 0), 2: (11, 0.25, 0), 3: (9, 0.25, 0)},\n",
       " 11: {0: (19, 0.25, 0), 1: (3, 0.25, 0), 2: (11, 0.25, 0), 3: (10, 0.25, 0)},\n",
       " 12: {0: (12, 0, 0), 1: (12, 0, 0), 2: (12, 0, 0), 3: (12, 0, 0)},\n",
       " 13: {0: (21, 0.25, 0), 1: (5, 0.25, 0), 2: (14, 0.25, 0), 3: (13, 0.25, 0)},\n",
       " 14: {0: (22, 0.25, 0), 1: (6, 0.25, 0), 2: (15, 0.25, 0), 3: (13, 0.25, 0)},\n",
       " 15: {0: (23, 0.25, 0), 1: (7, 0.25, 0), 2: (15, 0.25, 0), 3: (14, 0.25, 0)},\n",
       " 16: {0: (24, 0.25, 0), 1: (8, 0.25, 0), 2: (17, 0.25, 0), 3: (16, 0.25, 0)},\n",
       " 17: {0: (25, 0.25, 0), 1: (9, 0.25, 0), 2: (18, 0.25, 0), 3: (16, 0.25, 0)},\n",
       " 18: {0: (18, 0.25, 0), 1: (10, 0.25, 0), 2: (19, 0.25, 0), 3: (17, 0.25, 0)},\n",
       " 19: {0: (27, 0.25, 0), 1: (11, 0.25, 0), 2: (20, 0.25, 0), 3: (18, 0.25, 0)},\n",
       " 20: {0: (28, 0.25, 0), 1: (20, 0.25, 0), 2: (21, 0.25, 0), 3: (19, 0.25, 0)},\n",
       " 21: {0: (29, 0.25, 0), 1: (13, 0.25, 0), 2: (22, 0.25, 0), 3: (20, 0.25, 0)},\n",
       " 22: {0: (30, 0.25, 0), 1: (14, 0.25, 0), 2: (23, 0.25, 0), 3: (21, 0.25, 0)},\n",
       " 23: {0: (31, 0.25, 0), 1: (15, 0.25, 0), 2: (23, 0.25, 0), 3: (22, 0.25, 0)},\n",
       " 24: {0: (24, 0.25, 100),\n",
       "  1: (24, 0.25, 100),\n",
       "  3: (24, 0.25, 100),\n",
       "  2: (24, 0.25, 100)},\n",
       " 25: {0: (33, 0.25, 0), 1: (17, 0.25, 0), 2: (25, 0.25, 0), 3: (24, 0.25, 0)},\n",
       " 26: {0: (26, 0, 0), 1: (26, 0, 0), 2: (26, 0, 0), 3: (26, 0, 0)},\n",
       " 27: {0: (35, 0.25, 0), 1: (19, 0.25, 0), 2: (28, 0.25, 0), 3: (27, 0.25, 0)},\n",
       " 28: {0: (36, 0.25, 0), 1: (20, 0.25, 0), 2: (29, 0.25, 0), 3: (27, 0.25, 0)},\n",
       " 29: {0: (37, 0.25, 0), 1: (21, 0.25, 0), 2: (30, 0.25, 0), 3: (28, 0.25, 0)},\n",
       " 30: {0: (38, 0.25, 0), 1: (22, 0.25, 0), 2: (31, 0.25, 0), 3: (29, 0.25, 0)},\n",
       " 31: {0: (39, 0.25, 0), 1: (23, 0.25, 0), 2: (31, 0.25, 0), 3: (30, 0.25, 0)},\n",
       " 32: {0: (40, 0.25, 0), 1: (24, 0.25, 0), 2: (33, 0.25, 0), 3: (32, 0.25, 0)},\n",
       " 33: {0: (41, 0.25, 0), 1: (25, 0.25, 0), 2: (33, 0.25, 0), 3: (32, 0.25, 0)},\n",
       " 34: {0: (34, 0, 0), 1: (34, 0, 0), 2: (34, 0, 0), 3: (34, 0, 0)},\n",
       " 35: {0: (43, 0.25, 0), 1: (27, 0.25, 0), 2: (36, 0.25, 0), 3: (35, 0.25, 0)},\n",
       " 36: {0: (44, 0.25, 0), 1: (28, 0.25, 0), 2: (37, 0.25, 0), 3: (35, 0.25, 0)},\n",
       " 37: {0: (45, 0.25, 0), 1: (29, 0.25, 0), 2: (38, 0.25, 0), 3: (36, 0.25, 0)},\n",
       " 38: {0: (38, 0.25, 0), 1: (30, 0.25, 0), 2: (39, 0.25, 0), 3: (37, 0.25, 0)},\n",
       " 39: {0: (47, 0.25, 0), 1: (31, 0.25, 0), 2: (39, 0.25, 0), 3: (38, 0.25, 0)},\n",
       " 40: {0: (48, 0.25, 0), 1: (32, 0.25, 0), 2: (41, 0.25, 0), 3: (40, 0.25, 0)},\n",
       " 41: {0: (49, 0.25, 0), 1: (33, 0.25, 0), 2: (41, 0.25, 0), 3: (40, 0.25, 0)},\n",
       " 42: {0: (42, 0, 0), 1: (42, 0, 0), 2: (42, 0, 0), 3: (42, 0, 0)},\n",
       " 43: {0: (51, 0.25, 0), 1: (35, 0.25, 0), 2: (44, 0.25, 0), 3: (43, 0.25, 0)},\n",
       " 44: {0: (52, 0.25, 0), 1: (36, 0.25, 0), 2: (45, 0.25, 0), 3: (43, 0.25, 0)},\n",
       " 45: {0: (53, 0.25, 0), 1: (37, 0.25, 0), 2: (45, 0.25, 0), 3: (44, 0.25, 0)},\n",
       " 46: {0: (46, 0, 0), 1: (46, 0, 0), 2: (46, 0, 0), 3: (46, 0, 0)},\n",
       " 47: {0: (55, 0.25, 0), 1: (39, 0.25, 0), 2: (47, 0.25, 0), 3: (47, 0.25, 0)},\n",
       " 48: {0: (56, 0.25, 0), 1: (40, 0.25, 0), 2: (49, 0.25, 0), 3: (48, 0.25, 0)},\n",
       " 49: {0: (57, 0.25, 0), 1: (41, 0.25, 0), 2: (50, 0.25, 0), 3: (48, 0.25, 0)},\n",
       " 50: {0: (58, 0.25, 0), 1: (50, 0.25, 0), 2: (51, 0.25, 0), 3: (49, 0.25, 0)},\n",
       " 51: {0: (59, 0.25, 0), 1: (43, 0.25, 0), 2: (52, 0.25, 0), 3: (50, 0.25, 0)},\n",
       " 52: {0: (60, 0.25, 0), 1: (44, 0.25, 0), 2: (53, 0.25, 0), 3: (51, 0.25, 0)},\n",
       " 53: {0: (61, 0.25, 0), 1: (45, 0.25, 0), 2: (53, 0.25, 0), 3: (52, 0.25, 0)},\n",
       " 54: {0: (54, 0, 0), 1: (54, 0, 0), 2: (54, 0, 0), 3: (54, 0, 0)},\n",
       " 55: {0: (63, 0.25, 0), 1: (47, 0.25, 0), 2: (55, 0.25, 0), 3: (55, 0.25, 0)},\n",
       " 56: {0: (56, 0.25, 0), 1: (48, 0.25, 0), 2: (57, 0.25, 0), 3: (56, 0.25, 0)},\n",
       " 57: {0: (57, 0.25, 0), 1: (49, 0.25, 0), 2: (58, 0.25, 0), 3: (56, 0.25, 0)},\n",
       " 58: {0: (58, 0.25, 0), 1: (50, 0.25, 0), 2: (59, 0.25, 0), 3: (57, 0.25, 0)},\n",
       " 59: {0: (59, 0.25, 0), 1: (51, 0.25, 0), 2: (60, 0.25, 0), 3: (58, 0.25, 0)},\n",
       " 60: {0: (60, 0.25, 0), 1: (52, 0.25, 0), 2: (61, 0.25, 0), 3: (59, 0.25, 0)},\n",
       " 61: {0: (61, 0.25, 0), 1: (53, 0.25, 0), 2: (61, 0.25, 0), 3: (60, 0.25, 0)},\n",
       " 62: {0: (62, 0, 0), 1: (62, 0, 0), 2: (62, 0, 0), 3: (62, 0, 0)},\n",
       " 63: {0: (63, 0.25, 100),\n",
       "  1: (63, 0.25, 100),\n",
       "  3: (63, 0.25, 100),\n",
       "  2: (63, 0.25, 100)}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fcdb72",
   "metadata": {},
   "source": [
    "در قسمت اول از ما خواسته شده تا تابع مقدار یا همان ارزیابی سیاست را محاسبه کنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d426a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#محاسبه تابع مقدار(ارزیابی سیاست)\n",
    "def policy_evaluation(P,policy,threshold,dicount):\n",
    "    value=np.zeros((noS,)) # مقداردهی اولیه تابع مقدار\n",
    "    while True: # تا زمانی که همگرایی در تابع مقدار اتفاق نمی افتد حلقه را ادامه بده\n",
    "        new_value=np.zeros((noS,)) # v مقداردهی اولیه تابع بروزرسانی  \n",
    "\n",
    "        change=0\n",
    "        for s in S: # برای تمام حالات\n",
    "            v=0\n",
    "            \n",
    "            for a,action_prob in enumerate(policy[s]): #   برای تمامی اعمال و احتمال اعمال تحت سیاست مشخص در آن حالت\n",
    "                next_state,probability,reward=P[s][a] # برای 4 مقداری که از بودن عامل در آن حالت و انجام آن عمل در محیط\n",
    "                temp=probability*action_prob*(reward+discount*value[next_state]) # بروزرسانی تابع مقدار\n",
    "                v+=temp\n",
    "\n",
    "            change=max(change,np.abs(v-value[s])) # محاسبه اختلاف تابع مقدار جدید و قدیم\n",
    "            new_value[s]=v # در صورتی که شرط خاتمه برقرار، قرار دادن تابع مقدار در مقدار جدید \n",
    "\n",
    "        if change < threshold:\n",
    "              break\n",
    "\n",
    "        value=new_value\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d5b9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function for policy: all actions equiprobable: discount = 0.9 :\n",
      "[[7.54222620e-03 1.60728345e-03 2.07389049e-04 2.18052787e-05\n",
      "  1.38822059e-06 9.77573206e-08 3.53131494e-08 1.11906874e-07]\n",
      " [1.17392285e-01 1.92170293e-02 1.85043865e-03 1.57066851e-04\n",
      "  0.00000000e+00 2.16616887e-07 3.82811997e-07 1.73032866e-06]\n",
      " [1.94282242e+00 2.20786070e-01 1.33152018e-02 7.62988794e-04\n",
      "  4.59961037e-05 3.15378069e-06 4.82328793e-06 2.85363508e-05]\n",
      " [3.22580645e+01 1.94973103e+00 0.00000000e+00 4.59804548e-05\n",
      "  5.56983256e-06 5.03120381e-06 5.36743976e-05 4.72222936e-04]\n",
      " [1.94357604e+00 2.33303368e-01 0.00000000e+00 2.89122643e-06\n",
      "  2.01148324e-06 2.70456125e-05 4.72134084e-04 7.84064074e-03]\n",
      " [1.17519015e-01 2.10049952e-02 0.00000000e+00 5.16416516e-07\n",
      "  2.53030601e-07 1.63411762e-06 0.00000000e+00 1.30604171e-01]\n",
      " [7.12688470e-03 1.59475880e-03 9.61641988e-05 5.52006454e-06\n",
      "  3.36304432e-07 1.18219245e-07 0.00000000e+00 2.05280294e+00]\n",
      " [4.59513896e-04 1.23223434e-04 1.31426937e-05 1.11756095e-06\n",
      "  8.74310982e-08 1.30341757e-08 0.00000000e+00 3.22580645e+01]]\n"
     ]
    }
   ],
   "source": [
    "random_policy = np.ones([noS, noA])/noA #  سیاست انتخاب عمل تصادفی\n",
    "\n",
    "threshold = 0.0000000000001 # تعیین پارامتری با مقدار بسیار کم برای بررسی همگرایی\n",
    "discount = 0.9  #مقداردهی اولیه ضریب تخفیف\n",
    "\n",
    "random_policy_value=policy_evaluation(P,random_policy,threshold,discount)\n",
    "print ('Value Function for policy: all actions equiprobable: discount = 0.9 :')\n",
    "print (random_policy_value.reshape(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1f831",
   "metadata": {},
   "source": [
    "در اینجا همانطور که میبینید خانه هایی که دیوار در ان قرار دارد تابع مقدار ان برابر صفر است و هر چه به هدف نزدیک میشویم این مقدار بیشتر میشود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01747130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function for policy: all actions equiprobable: discount = 0.1: \n",
      "[[6.42202489e-06 1.59553483e-07 2.24700919e-09 2.50882003e-11\n",
      "  1.58324838e-13 1.04773790e-15 2.91038305e-16 1.01281330e-14]\n",
      " [1.01452038e-03 1.89447334e-05 1.97696674e-07 1.74217281e-09\n",
      "  0.00000000e+00 2.01398507e-14 3.99886630e-14 1.60781201e-12]\n",
      " [1.61283374e-01 2.01627972e-03 1.26827465e-05 7.92842841e-08\n",
      "  4.98701527e-10 3.17668309e-12 4.79252776e-12 2.55632855e-10]\n",
      " [2.56410256e+01 1.61289753e-01 0.00000000e+00 4.98701353e-10\n",
      "  6.27362169e-12 4.82151518e-12 5.08050784e-10 4.06394019e-08]\n",
      " [1.61283453e-01 2.02888269e-03 0.00000000e+00 3.14688077e-12\n",
      "  1.64646190e-12 2.54045648e-10 4.06393920e-08 6.46090185e-06]\n",
      " [1.01452187e-03 1.91419126e-05 0.00000000e+00 5.91971911e-14\n",
      "  2.07801349e-14 1.59774208e-12 0.00000000e+00 1.02720212e-03]\n",
      " [6.38189813e-06 1.59537940e-07 1.00350962e-09 6.27280679e-12\n",
      "  3.92901711e-14 1.02445483e-14 0.00000000e+00 1.62291474e-01]\n",
      " [4.03997148e-08 1.25755544e-09 1.42199569e-11 1.28522515e-13\n",
      "  9.89530236e-16 5.82076609e-17 0.00000000e+00 2.56410256e+01]]\n"
     ]
    }
   ],
   "source": [
    "random_policy = np.ones([64, 4])/4 #  سیاست انتخاب عمل تصادفی\n",
    "\n",
    "threshold = 0.0000000000001 # تعیین پارامتری با مقدار بسیار کم برای بررسی همگرایی\n",
    "discount = 0.1  #مقداردهی اولیه ضریب تخفیف\n",
    "\n",
    "random_policy_value=policy_evaluation(P,random_policy,threshold,discount)\n",
    "print ('Value Function for policy: all actions equiprobable: discount = 0.1: ')\n",
    "print (random_policy_value.reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af936bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function for policy: all actions equiprobable: discount = 1 \n",
      "[[1.10922243e-02 2.61142035e-03 3.75549654e-04 4.41591005e-05\n",
      "  3.17220145e-06 2.51719882e-07 9.33807478e-08 2.64213731e-07]\n",
      " [1.52679720e-01 2.77035312e-02 2.97766536e-03 2.83664652e-04\n",
      "  0.00000000e+00 5.10216106e-07 8.84777657e-07 3.60561153e-06]\n",
      " [2.25140005e+00 2.84987694e-01 1.92799003e-02 1.23314531e-03\n",
      "  8.33999907e-05 6.51674412e-06 9.94723419e-06 5.29351816e-05]\n",
      " [3.33333333e+01 2.26141962e+00 0.00000000e+00 8.33601036e-05\n",
      "  1.13378017e-05 1.04104650e-05 9.88190437e-05 7.80474878e-04]\n",
      " [2.25261419e+00 3.02973214e-01 0.00000000e+00 5.91843768e-06\n",
      "  4.23426765e-06 4.98938510e-05 7.80272123e-04 1.15553689e-02]\n",
      " [1.52906363e-01 3.05643930e-02 0.00000000e+00 1.18219406e-06\n",
      "  5.98192172e-07 3.38476089e-06 0.00000000e+00 1.71769787e-01]\n",
      " [1.04168537e-02 2.58631803e-03 1.74957368e-04 1.12162812e-05\n",
      "  7.69852207e-07 2.79370213e-07 0.00000000e+00 2.39322165e+00]\n",
      " [7.60124158e-04 2.24884560e-04 2.68262008e-05 2.55108491e-06\n",
      "  2.23791813e-07 3.59401416e-08 0.00000000e+00 3.33333333e+01]]\n"
     ]
    }
   ],
   "source": [
    "random_policy = np.ones([64, 4])/4 #  سیاست انتخاب عمل تصادفی\n",
    "\n",
    "threshold = 0.0000000000001 # تعیین پارامتری با مقدار بسیار کم برای بررسی همگرایی\n",
    "discount = 1  #مقداردهی اولیه ضریب تخفیف\n",
    "\n",
    "random_policy_value=policy_evaluation(P,random_policy,threshold,discount)\n",
    "print ('Value Function for policy: all actions equiprobable: discount = 1 ')\n",
    "print (random_policy_value.reshape(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41e78f",
   "metadata": {},
   "source": [
    "با تغییر اندازه مقدار ضریب تخفیف به این نتیجه رسیدیم که"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed70bf1",
   "metadata": {},
   "source": [
    "اگر ضریب تخفیف را روی یک مقدار کوچک تنظیم کنیم یعنی نزدیک به صفر انگاه به پاداش های فوری اهمیت بیشتری میدهیم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f761f",
   "metadata": {},
   "source": [
    "اگر ضریب تخفیف را روی یک مقدار بزرگ تنظیم کنیم یعنی نزدیک به یک انگاه پاداش های اینده اهمیت بیشتری پیدا میکنند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c6b23",
   "metadata": {},
   "source": [
    "# سوال دوم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb7c5e",
   "metadata": {},
   "source": [
    "در این قسمت از ما خواسته شده مقدار تکرار سیاست را به دست اوریم که شامل 3 بخش میشود محاسبه تابع مقدار یا همان ارزیابی سیاست "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c671aa",
   "metadata": {},
   "source": [
    "محاسبه استخراج سیاست یا بهبود سیاست و در اخر الگوریتم تکرار سیاست است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "665bd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#الگوریتم تکرار سیاست\n",
    "def policy_iteration(P,discount,threshold):\n",
    "   \n",
    "    value=np.zeros((noS,)) #مقدار دهی اولیه تابع مقدار\n",
    "    policy=np.ones([64, 4])/4 # مقدار دهی اولیه سیاست\n",
    "    \n",
    "    while True:\n",
    "        #محاسبه تابع مقدار یا ارزیابی سیاست\n",
    "        value=policy_evaluation(P,policy,threshold,discount) #فراخوانی تابع مقدار حالت \n",
    "        \n",
    "        new_value=np.zeros((noS,)) #مقدار دهی اولیه \n",
    "        new_policy=np.zeros([noS,4]) #مقدار دهی اولیه\n",
    "        \n",
    "        #محاسبه استخراج سیاست یا بهبود سیاست\n",
    "        policy_stable=True\n",
    "        for s in S: #برای هر حالت  Q محاسبه\n",
    "            \n",
    "            old_action=policy[s]\n",
    "            action_values = np.zeros(noA)\n",
    "            for a in range(noA):   #برای هر عمل  Q محاسبه    \n",
    "                    next_state,probability,reward = P[s][a] # MDPبدست آوردن دانش\n",
    "                    action_values[a] += probability*(reward + discount*value[next_state]) # Q محاسبه و بروز رسانی مقادیر \n",
    "            max_total = np.amax(action_values)   #  انتخاب بیشترین مقدار تابع عمل وحالت - انتخاب سیاست حریصانه \n",
    "            best_a = np.argmax(action_values)\n",
    "\n",
    "            new_policy[s][best_a]=1 #قرار دادن مقدار یک مقابل عملی که بهینه است\n",
    "\n",
    "            new_value[s]=max_total  \n",
    "            if (np.array_equal(old_action,new_policy[s])!=True):\n",
    "                policy_stable=False\n",
    "                    \n",
    "        value=new_value\n",
    "        \n",
    "        if policy_stable: #مقدار برای مقادیری که دیوار است\n",
    "            value[wall]=12,26,34,42,46,54,62\n",
    "            return new_policy,value  #  برگرداندن مقدار سیاست بهینه\n",
    "        else:\n",
    "            policy=new_policy # جایگزین کردن سیاست قبلی با سیاست بعدی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6cd99fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_policy,corr_value=policy_iteration(P,discount,threshold) # فراخوانی تابع تکرار سیاست "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f78c3f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ae3b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.20833333e-01, 1.30208333e-01, 3.25520833e-02, 8.13802083e-03,\n",
       "        2.03450521e-03, 5.08626302e-04, 5.08626302e-04, 2.03450521e-03],\n",
       "       [2.08333333e+00, 5.20833333e-01, 1.30208333e-01, 3.25520833e-02,\n",
       "        0.00000000e+00, 2.03450521e-03, 2.03450521e-03, 8.13802083e-03],\n",
       "       [8.33333333e+00, 2.08333333e+00, 5.20833333e-01, 1.30208333e-01,\n",
       "        3.25520833e-02, 8.13802083e-03, 8.13802083e-03, 3.25520833e-02],\n",
       "       [3.33333333e+01, 8.33333333e+00, 0.00000000e+00, 3.25520833e-02,\n",
       "        8.13802083e-03, 8.13802083e-03, 3.25520833e-02, 1.30208333e-01],\n",
       "       [8.33333333e+00, 2.08333333e+00, 0.00000000e+00, 8.13802083e-03,\n",
       "        8.13802083e-03, 3.25520833e-02, 1.30208333e-01, 5.20833333e-01],\n",
       "       [2.08333333e+00, 5.20833333e-01, 0.00000000e+00, 2.03450521e-03,\n",
       "        2.03450521e-03, 8.13802083e-03, 0.00000000e+00, 2.08333333e+00],\n",
       "       [5.20833333e-01, 1.30208333e-01, 3.25520833e-02, 8.13802083e-03,\n",
       "        2.03450521e-03, 2.03450521e-03, 0.00000000e+00, 8.33333333e+00],\n",
       "       [1.30208333e-01, 3.25520833e-02, 8.13802083e-03, 2.03450521e-03,\n",
       "        5.08626302e-04, 5.08626302e-04, 0.00000000e+00, 3.33333333e+01]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_value  # چاپ تابع مقدار بهینه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df1ea157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b1e068da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#را برای بهتر دیده شدن به صورت زیر هم میشود قرار داد  best_policy \n",
    "optimal_policy_function=np.zeros([64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "477355b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    for j in range(4):\n",
    "        if (best_policy[i][j]==1):\n",
    "            optimal_policy_function[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ea85225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 3., 3., 3., 3., 0., 0., 0., 3., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 2., 2., 2., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 3.,\n",
       "       3., 3., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_policy_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677729af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d8dd6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_policy=\n",
      " [['^' '^' '^' '^' '>' '^' '^' '^']\n",
      " ['^' '^' '^' '^' '^' '^' '^' '^']\n",
      " ['^' '^' '>' '>' '>' '>' '^' '^']\n",
      " ['^' '>' '^' 'v' 'v' '^' '^' '^']\n",
      " ['v' 'v' '^' 'v' '<' '<' '<' '^']\n",
      " ['v' 'v' '^' '^' 'v' 'v' '^' '^']\n",
      " ['v' 'v' '>' '>' '>' 'v' '^' '^']\n",
      " ['v' 'v' 'v' 'v' 'v' 'v' '^' '^']]\n"
     ]
    }
   ],
   "source": [
    "map_act = {0:'^', 1:'v', 2:'<', 3:'>'}                                              # جهت مشخص تر شدن نمایش\n",
    "optimal_policy = (np.array([map_act[x] for x in optimal_policy_function])).reshape([8,-1])  # چاپ سیاست بهینه\n",
    "\n",
    "print(\"optimal_policy=\\n\",optimal_policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45c284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7581e022",
   "metadata": {},
   "source": [
    "# سوال سوم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86c3e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#الگوریتم تکرار مقدار\n",
    "\n",
    "def value_iteration(P,discount,threshold):\n",
    "    value=np.zeros((noS,)) #مقداردهی اولیه تابع مقدار\n",
    "    while True:\n",
    "        new_policy=np.zeros([noS,4]) # مقدار دهی اولیه سیاست\n",
    "        change=0\n",
    "        for s in S: # محاسبه برای تمامی حالات\n",
    "            v=value[s]\n",
    "            action_values = np.zeros(noA)\n",
    "            for a in range(4):   #محاسبه هر عمل\n",
    "                next_state,probability,reward = P[s][a] # MDPبدست آوردن دانش \n",
    "                action_values[a] += probability*(reward + discount*value[next_state]) #محاسبه و بروز رسانی مقادیر \n",
    "            max_total = np.amax(action_values)   # انتخاب بیشترین مقدار پاداش ---انتخاب حریصانه\n",
    "            best_a = np.argmax(action_values)\n",
    "\n",
    "            value[s]=max_total\n",
    "            new_policy[s][best_a]=1 #قرار دادن مقدار یک مقابل عملی که بهینه است\n",
    "\n",
    "            change=max(change,np.abs(v-value[s])) #محاسبه اختلاف تابع مقدار جدید و قدیم\n",
    "            \n",
    "        if change < threshold:\n",
    "              break\n",
    "    return new_policy,value.reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "817155d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_policy,corr_value=value_iteration(P,discount,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef5dc340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.20833333e-01, 1.30208333e-01, 3.25520833e-02, 8.13802083e-03,\n",
       "        2.03450521e-03, 5.08626302e-04, 5.08626302e-04, 2.03450521e-03],\n",
       "       [2.08333333e+00, 5.20833333e-01, 1.30208333e-01, 3.25520833e-02,\n",
       "        0.00000000e+00, 2.03450521e-03, 2.03450521e-03, 8.13802083e-03],\n",
       "       [8.33333333e+00, 2.08333333e+00, 5.20833333e-01, 1.30208333e-01,\n",
       "        3.25520833e-02, 8.13802083e-03, 8.13802083e-03, 3.25520833e-02],\n",
       "       [3.33333333e+01, 8.33333333e+00, 0.00000000e+00, 3.25520833e-02,\n",
       "        8.13802083e-03, 8.13802083e-03, 3.25520833e-02, 1.30208333e-01],\n",
       "       [8.33333333e+00, 2.08333333e+00, 0.00000000e+00, 8.13802083e-03,\n",
       "        8.13802083e-03, 3.25520833e-02, 1.30208333e-01, 5.20833333e-01],\n",
       "       [2.08333333e+00, 5.20833333e-01, 0.00000000e+00, 2.03450521e-03,\n",
       "        2.03450521e-03, 8.13802083e-03, 0.00000000e+00, 2.08333333e+00],\n",
       "       [5.20833333e-01, 1.30208333e-01, 3.25520833e-02, 8.13802083e-03,\n",
       "        2.03450521e-03, 2.03450521e-03, 0.00000000e+00, 8.33333333e+00],\n",
       "       [1.30208333e-01, 3.25520833e-02, 8.13802083e-03, 2.03450521e-03,\n",
       "        5.08626302e-04, 5.08626302e-04, 0.00000000e+00, 3.33333333e+01]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b14205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2ca84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940e179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
